#Crop patches and model creation script

#Packages necessary
#%%
import os
import gc
import warnings
warnings.filterwarnings('ignore')
import glob
from shutil import copyfile, copy2
import pandas as pd
import numpy as np
from skimage import io
from keras.models import Model
from keras.applications.nasnet import NASNetMobile
from keras.applications.nasnet import NASNetLarge
from keras.layers import Input, Dense, BatchNormalization, Activation, Dropout
from tensorflow.keras import optimizers
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.model_selection import cross_val_score
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split, KFold

# %%
#Label names
Labels = {'D_coral' : 0,
          'LICO' : 1,
          'Rubble_cor' : 2,
          'Sed_dropst' : 3}

#%%


#Import images and manual labels
imgs = glob.glob("FILEPATH//*.png")
labs = glob.glob("FILEPATH//*.txt")

#Concatonate into dataframe
data = pd.DataFrame(data = list(zip(imgs, labs)), columns = ['images', 'cpce'])

dest = "FILEPATH FOR WHERE PATCHES WILL BE STORED"


#Create folders for patches
for l in Labels:
    if(not os.path.exists(dest + "/" + l)):
        os.mkdir(dest + "/" + l)


#Create cropping, dimension and extract patches functions
def crop_patch(image, y, x):
    size = 112
    
    patch = image[abs(size - y) : abs(size + y), abs(size - x) : abs(size + x), :]
    
    return patch

def check_dimensions(image, y, x):
    
    size = 224
    
    height, width = image.shape[0:2]
    if(x + (size//2) > width or x - (size//2) < 0 or y + (size//2) > height or y - (size//2) < 0):
        return False
    else:
        return True
    
def extract_patches(data):
    
    for i in range(len(data)):
        each_image = io.imread(data['images'][i])
        each_image = each_image[:,:,:-1]
        each_annotation = pd.read_csv(data['cpce'][i], sep = ",", 
                                      engine = 'python').rename(columns={'# Row' : 'Y', 'Col': 'X'})
        
        file_name = (data['cpce'][i].split("\\")[-1].split(".")[0]);

        height, width = each_image.shape[0:2]
        
        for index, row in each_annotation.iterrows():
            
            X = int(row[1])
            Y = int(row[0])
            L = str(row[2])
        
            
            if(L not in Labels):  # changed LABELS to labels
                continue
            
            if(check_dimensions(each_image, Y, X)):
                patch = crop_patch(each_image, Y, X)
              
            else:
                continue      

            io.imsave(arr = patch, fname = dest + "\\" + L +  "\\" + file_name + "_" + str(index) + ".png")
            
    print("Complete")       
    
#extract_patches(data) # <------------------------- #Hash used so patches wont be created everytime the script is run


#Import patches and create dataframe with the labels
patches = glob.glob("/mnt/gpuws/daviddalton/Patches//**//*.png", recursive= True)
labels = [patch.split("/")[-2] for patch in patches]
data = pd.DataFrame(data = list(zip(patches, labels)), columns = ['images', 'labels'])

#Over and undersampling of the classes to 7500
#%%
df_class_0 = data[data['labels'] == 'Sed_dropst']
df_class_1 = data[data['labels'] == 'Rubble_cor']
df_class_2 = data[data['labels'] == 'D_coral']
df_class_3 = data[data['labels'] == 'LICO']

df_class_0_under = df_class_0.sample(7500)
df_class_3_over = df_class_3.sample(7500, replace = True)
df_class_1_over = df_class_1.sample(7500, replace = True)
df_class_2_over = df_class_2.sample(7500, replace = True)

sampled_data = pd.concat([df_class_0_under, df_class_1_over, df_class_2_over, df_class_3_over], axis = 0)



#%%
#Training the CNN model

train, valid = train_test_split(sampled_data, test_size = .125)
test = sampled_data
print("Training:", len(train), "Validation:", len(valid), "Testing:", len(test))

batch_size = 32

# Training images are augmented, and then lightly pre-processed
train_augmentor = ImageDataGenerator(preprocessing_function = None, 
                                            horizontal_flip = True, 
                                            vertical_flip = True,
                                            rescale = 1.0/255.0)      
                                     
                                                                   
# Reading the training set from dataframe
train_generator = train_augmentor.flow_from_dataframe(dataframe = train, directory = None,
                                                      x_col = 'images', y_col = 'labels', target_size = (224, 224), 
                                                      color_mode = "rgb",  class_mode = 'categorical', 
                                                      batch_size = batch_size, shuffle = True, seed = 42)
                                                     

# Only pre-process images, no augmentation
validate_augmentor = ImageDataGenerator( preprocessing_function = None,
                                            rescale = 1.0/255.0)

                          
validation_generator = validate_augmentor.flow_from_dataframe(dataframe = valid, directory = None, 
                                                              x_col = 'images', y_col = 'labels', target_size = (224, 224), 
                                                              color_mode = "rgb",  class_mode = 'categorical', 
                                                              batch_size = batch_size, shuffle = True, seed = 42)


# %%
num_epochs = 40

# Defines the length of an epoch, all images used
steps_per_epoch_train = (len(train)/batch_size)

# Defines the length of an epoch, all images used
steps_per_epoch_valid = (len(valid)/batch_size)


#%%
# # Transfer-learning model
main_input = Input(shape = (224, 224, 3))
base = NASNetMobile(include_top = False, weights = 'imagenet', pooling = 'max')(main_input)
x = Dropout(.75)(base)
x = Dense(4)(x)
main_output = Activation('softmax')(x)

model = Model(inputs = [main_input], outputs = [main_output])

# %%
learning_rate = 0.0001

model.compile(loss = 'categorical_crossentropy',
              optimizer = optimizers.Adam(lr = learning_rate), 
              metrics = ['acc'])

# %%
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau

rate_schedule = lambda e: 0.0001

holla = [
         LearningRateScheduler(rate_schedule),      
         ModelCheckpoint(filepath = "/mnt/gpuws/daviddalton/Model/ReduceLR_model_Over.hdf5", 
                         monitor = 'val_loss', 
                         save_weights_only = True, 
                         save_best_only = True, verbose = 1,),
         EarlyStopping(monitor = 'val_loss',restore_best_weights = True,
                         patience = 5),
         ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience=2)
        ]

# %%
# Starts training, saves info for later
history = model.fit_generator(train_generator, 
                              steps_per_epoch = steps_per_epoch_train, 
                              epochs = num_epochs, 
                              validation_data = validation_generator, 
                              validation_steps = steps_per_epoch_valid,
                              callbacks = holla,
                              verbose = 1)


#%%
#Load the saved model
model.load_weights("/mnt/gpuws/daviddalton/Model/ReduceLR_model_Over.hdf5")

# Reads from dataframe for holdout set
test_generator = validate_augmentor.flow_from_dataframe(dataframe = test,
                                                 x_col = 'images', y_col = 'labels', target_size = (224, 224), 
                                                 color_mode = "rgb",  class_mode = 'categorical', 
                                                 batch_size = batch_size, shuffle = False)
# Defines the length of an epoch for test set
steps_per_epoch_test = len(test)/batch_size

#%%
# Get performance metrics and confusion matrix
predictions = model.predict_generator(test_generator, steps = steps_per_epoch_test)
predict_classes = np.argmax(predictions, axis = 1)

test_y = test_generator.classes
print("# of images:", len(predict_classes))
print(accuracy_score(y_true = test_y, y_pred = predict_classes))
print(confusion_matrix(y_true = test_y, y_pred = predict_classes))
print(classification_report(y_true = test_y, y_pred = predict_classes))
